{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watch gyro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user activity             time         x         y             z\n",
      "0      1639        A  182803804703000   0.36432 -0.879908     1.212271;\n",
      "1      1639        A  182803845121000 -0.797883  1.950499  -0.39414784;\n",
      "2      1639        A  182803885538000  0.335558   2.55983   -1.7896442;\n",
      "3      1639        A  182803925089000  1.030111 -0.428236   -1.3283848;\n",
      "4      1639        A  182803965213000 -2.098571  1.634116    -1.160073;\n",
      "...     ...      ...              ...       ...       ...           ...\n",
      "64874  1610        S   18917068249901  -0.50843  0.602261  0.061357632;\n",
      "64875  1610        S   18917118178041  0.014615  0.945276  -0.16980475;\n",
      "64876  1610        S   18917168106181  3.126252  1.933841  -0.83666027;\n",
      "64877  1610        S   18917218034321  3.550228  2.166069    -1.326682;\n",
      "64878  1610        S   18917267962461  4.390721  2.102153   -1.6675665;\n",
      "\n",
      "[3440342 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3440342 entries, 0 to 64878\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   user      object \n",
      " 1   activity  object \n",
      " 2   time      object \n",
      " 3   x         float64\n",
      " 4   y         float64\n",
      " 5   z         float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 183.7+ MB\n"
     ]
    }
   ],
   "source": [
    "columns=['user','activity','time','x','y','z']\n",
    "data_watch_gyro_sum = pd.DataFrame(data=None,columns=columns)\n",
    "for dirname, _, filenames in os.walk('wisdm/wisdm-dataset/wisdm-dataset/raw/watch/gyro'):\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv('wisdm/wisdm-dataset/wisdm-dataset/raw/watch/gyro/'+filename , sep=\",\", header=None)\n",
    "        temp=pd.DataFrame(data=df.values, columns=columns)\n",
    "        data_watch_gyro_sum=pd.concat([data_watch_gyro_sum,temp])\n",
    "print(data_watch_gyro_sum)\n",
    "\n",
    "data_watch_gyro_sum['z'] = data_watch_gyro_sum['z'].str.replace(';','')\n",
    "data_watch_gyro_sum['x']=data_watch_gyro_sum['x'].astype('float')\n",
    "data_watch_gyro_sum['y']=data_watch_gyro_sum['y'].astype('float')\n",
    "data_watch_gyro_sum['z']=data_watch_gyro_sum['z'].astype('float')\n",
    "\n",
    "data_watch_gyro_sum['activity'].value_counts()\n",
    "data_watch_gyro_sum.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phone gyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3608635 entries, 0 to 64251\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   user      object \n",
      " 1   activity  object \n",
      " 2   time      object \n",
      " 3   x         float64\n",
      " 4   y         float64\n",
      " 5   z         float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 192.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_phone_gyro_sum = pd.DataFrame(data=None,columns=columns)\n",
    "for dirname, _, filenames in os.walk('wisdm/wisdm-dataset/wisdm-dataset/raw/phone/gyro'):\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv('wisdm/wisdm-dataset/wisdm-dataset/raw/phone/gyro/'+filename , sep=\",\", header=None)\n",
    "        temp=pd.DataFrame(data=df.values, columns=columns)\n",
    "        data_phone_gyro_sum=pd.concat([data_phone_gyro_sum,temp])\n",
    "\n",
    "data_phone_gyro_sum['z'] = data_phone_gyro_sum['z'].str.replace(';','')\n",
    "\n",
    "data_phone_gyro_sum['x']=data_phone_gyro_sum['x'].astype('float')\n",
    "data_phone_gyro_sum['y']=data_phone_gyro_sum['y'].astype('float')\n",
    "data_phone_gyro_sum['z']=data_phone_gyro_sum['z'].astype('float')\n",
    "\n",
    "data_phone_gyro_sum['activity'].value_counts()\n",
    "data_phone_gyro_sum.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watch accelrometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user activity              time         x         y            z\n",
      "0       1619        A   351205245071760  9.306112 -1.640178   -2.385074;\n",
      "1       1619        A   351205294571760  8.958953 -1.609053  -2.3108535;\n",
      "2       1619        A   351205344071760  8.044368 -0.943465   -2.282123;\n",
      "3       1619        A   351205393571760   8.84882 -0.177321  -2.5981576;\n",
      "4       1619        A   351205443071760  8.173655 -0.117466   -2.459294;\n",
      "...      ...      ...               ...       ...       ...          ...\n",
      "160794  1638        S  1135293554939000 -4.071533  -7.89159  -1.3747413;\n",
      "160795  1638        S  1135293575112000 -3.877537 -7.846084  -1.4370118;\n",
      "160796  1638        S  1135293595208000   -3.7027  -7.91554  -1.5687379;\n",
      "160797  1638        S  1135293615414000 -3.578159 -8.176597  -1.8130299;\n",
      "160798  1638        S  1135293635510000 -3.499124 -8.449629  -1.8968556;\n",
      "\n",
      "[3710454 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3710454 entries, 0 to 160798\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   user      object \n",
      " 1   activity  object \n",
      " 2   time      object \n",
      " 3   x         float64\n",
      " 4   y         float64\n",
      " 5   z         float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 198.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_watch_accel_sum = pd.DataFrame(data=None,columns=columns)\n",
    "for dirname, _, filenames in os.walk('wisdm/wisdm-dataset/wisdm-dataset/raw/watch/accel'):\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv('wisdm/wisdm-dataset/wisdm-dataset/raw/watch/accel/'+filename , sep=\",\", header=None)\n",
    "        temp=pd.DataFrame(data=df.values, columns=columns)\n",
    "        data_watch_accel_sum=pd.concat([data_watch_accel_sum,temp])\n",
    "\n",
    "print(data_watch_accel_sum)\n",
    "\n",
    "data_watch_accel_sum['z'] = data_watch_accel_sum['z'].str.replace(';','')\n",
    "data_watch_accel_sum['x']=data_watch_accel_sum['x'].astype('float')\n",
    "data_watch_accel_sum['y']=data_watch_accel_sum['y'].astype('float')\n",
    "data_watch_accel_sum['z']=data_watch_accel_sum['z'].astype('float')\n",
    "\n",
    "data_watch_accel_sum['activity'].value_counts()\n",
    "data_watch_accel_sum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phone_watch = pd.DataFrame(data=None, columns=columns)\n",
    "df_phone_watch['user']= data_watch_accel_sum['user'].head(3440342)\n",
    "df_watch['activity']= data_watch_accel_sum['activity'].head(3440342)\n",
    "df_watch['time']= data_watch_accel_sum['time'].head(3440342)\n",
    "df_watch['x'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['x'].head(3440342).values\n",
    "df_watch['y'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['y'].head(3440342).values\n",
    "df_watch['z'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['z'].head(3440342).values\n",
    "\n",
    "df_watch['activity'].value_counts()\n",
    "df_watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phone accelrometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['user','activity','time','x','y','z']\n",
    "\n",
    "data_phone_accel_sum = pd.DataFrame(data=None,columns=columns)\n",
    "for dirname, _, filenames in os.walk('wisdm/wisdm-dataset/wisdm-dataset/raw/phone/accel'):\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv('wisdm/wisdm-dataset/wisdm-dataset/raw/phone/accel/'+filename , sep=\",\", header=None)\n",
    "        temp=pd.DataFrame(data=df.values, columns=columns)\n",
    "        data_phone_accel_sum=pd.concat([data_phone_accel_sum,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4804403 entries, 0 to 80869\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   user      object \n",
      " 1   activity  object \n",
      " 2   time      object \n",
      " 3   x         float64\n",
      " 4   y         float64\n",
      " 5   z         float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 256.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_phone_accel_sum['z'] = data_phone_accel_sum['z'].str.replace(';','')\n",
    "data_phone_accel_sum['activity'].value_counts()\n",
    "data_phone_accel_sum['x']=data_phone_accel_sum['x'].astype('float')\n",
    "data_phone_accel_sum['y']=data_phone_accel_sum['y'].astype('float')\n",
    "data_phone_accel_sum['z']=data_phone_accel_sum['z'].astype('float')\n",
    "data_phone_accel_sum.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine phone accelerometer and gyroscope data\n",
    "df_phone = pd.DataFrame(data=None, columns=columns)\n",
    "df_phone['user']= data_phone_accel_sum['user'].head(3608635)\n",
    "df_phone['activity']= data_phone_accel_sum['activity'].head(3608635)\n",
    "df_phone['time']= data_phone_accel_sum['time'].head(3608635)\n",
    "df_phone['x'] = data_phone_gyro_sum['x'].values + data_phone_accel_sum['x'].head(3608635).values\n",
    "df_phone['y'] = data_phone_gyro_sum['y'].values + data_phone_accel_sum['y'].head(3608635).values\n",
    "df_phone['z'] = data_phone_gyro_sum['z'].values + data_phone_accel_sum['z'].head(3608635).values\n",
    "\n",
    "# combine watch and phone data\n",
    "df_watch = pd.DataFrame(data=None, columns=columns)\n",
    "df_watch['user']= data_watch_accel_sum['user'].head(3440342)\n",
    "df_watch['activity']= data_watch_accel_sum['activity'].head(3440342)\n",
    "df_watch['time']= data_watch_accel_sum['time'].head(3440342)\n",
    "df_watch['x'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['x'].head(3440342).values\n",
    "df_watch['y'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['y'].head(3440342).values\n",
    "df_watch['z'] = data_watch_gyro_sum['x'].values + data_watch_accel_sum['z'].head(3440342).values\n",
    "\n",
    "# combine phone and watch data\n",
    "\n",
    "df_phone_watch = pd.DataFrame(data=None, columns=columns)\n",
    "df_phone_watch['user']= df_phone['user'].head(3440342)\n",
    "df_phone_watch['activity']= df_phone['activity'].head(3440342)\n",
    "df_phone_watch['time']= df_phone['time'].head(3440342)\n",
    "df_phone_watch['x'] = df_watch['x'].values + df_phone['x'].head(3440342).values\n",
    "df_phone_watch['y'] = df_watch['y'].values + df_phone['y'].head(3440342).values\n",
    "df_phone_watch['z'] = df_watch['z'].values + df_phone['z'].head(3440342).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A\n",
       "1        A\n",
       "2        A\n",
       "3        A\n",
       "4        A\n",
       "        ..\n",
       "17033    G\n",
       "17034    G\n",
       "17035    G\n",
       "17036    G\n",
       "17037    G\n",
       "Name: activity, Length: 3440342, dtype: object"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change H, I, J to H\n",
    "df_watch['activity'] = df_watch['activity'].replace(['H', 'I', 'J', 'L'], 'H')\n",
    "df_watch['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1631</td>\n",
       "      <td>A</td>\n",
       "      <td>1553872620859145</td>\n",
       "      <td>6.418503</td>\n",
       "      <td>-0.319990</td>\n",
       "      <td>-0.820251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1631</td>\n",
       "      <td>A</td>\n",
       "      <td>1553872671213149</td>\n",
       "      <td>1.897995</td>\n",
       "      <td>0.260517</td>\n",
       "      <td>1.248988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1631</td>\n",
       "      <td>A</td>\n",
       "      <td>1553872721567153</td>\n",
       "      <td>3.882475</td>\n",
       "      <td>8.674672</td>\n",
       "      <td>4.740116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1631</td>\n",
       "      <td>A</td>\n",
       "      <td>1553872771921157</td>\n",
       "      <td>8.737418</td>\n",
       "      <td>18.673672</td>\n",
       "      <td>6.291784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1631</td>\n",
       "      <td>A</td>\n",
       "      <td>1553872822275160</td>\n",
       "      <td>0.361378</td>\n",
       "      <td>7.068919</td>\n",
       "      <td>2.413328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80864</th>\n",
       "      <td>1635</td>\n",
       "      <td>K</td>\n",
       "      <td>678056837857840</td>\n",
       "      <td>1.672455</td>\n",
       "      <td>-9.318509</td>\n",
       "      <td>-3.728840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80865</th>\n",
       "      <td>1635</td>\n",
       "      <td>K</td>\n",
       "      <td>678056857999441</td>\n",
       "      <td>1.595450</td>\n",
       "      <td>-9.392568</td>\n",
       "      <td>-3.731182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80866</th>\n",
       "      <td>1635</td>\n",
       "      <td>K</td>\n",
       "      <td>678056878141043</td>\n",
       "      <td>1.693974</td>\n",
       "      <td>-9.052802</td>\n",
       "      <td>-3.744604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80867</th>\n",
       "      <td>1635</td>\n",
       "      <td>K</td>\n",
       "      <td>678056898282644</td>\n",
       "      <td>1.760324</td>\n",
       "      <td>-9.303151</td>\n",
       "      <td>-3.881280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80868</th>\n",
       "      <td>1635</td>\n",
       "      <td>K</td>\n",
       "      <td>678056918424246</td>\n",
       "      <td>1.792389</td>\n",
       "      <td>-9.450188</td>\n",
       "      <td>-3.793116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042434 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user activity              time         x          y         z\n",
       "0      1631        A  1553872620859145  6.418503  -0.319990 -0.820251\n",
       "1      1631        A  1553872671213149  1.897995   0.260517  1.248988\n",
       "2      1631        A  1553872721567153  3.882475   8.674672  4.740116\n",
       "3      1631        A  1553872771921157  8.737418  18.673672  6.291784\n",
       "4      1631        A  1553872822275160  0.361378   7.068919  2.413328\n",
       "...     ...      ...               ...       ...        ...       ...\n",
       "80864  1635        K   678056837857840  1.672455  -9.318509 -3.728840\n",
       "80865  1635        K   678056857999441  1.595450  -9.392568 -3.731182\n",
       "80866  1635        K   678056878141043  1.693974  -9.052802 -3.744604\n",
       "80867  1635        K   678056898282644  1.760324  -9.303151 -3.881280\n",
       "80868  1635        K   678056918424246  1.792389  -9.450188 -3.793116\n",
       "\n",
       "[1042434 rows x 6 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fs = 20\n",
    "\n",
    "# df_watch = df_watch.drop(['user', 'time'], axis=1)\n",
    "\n",
    "df_a = df_phone_watch[df_phone_watch['activity']=='A'].head(174604)\n",
    "df_k = df_phone_watch[df_phone_watch['activity']=='K'].head(174604)\n",
    "df_e = df_phone_watch[df_phone_watch['activity']=='E'].head(174604)\n",
    "df_d = df_phone_watch[df_phone_watch['activity']=='D'].head(174604)\n",
    "df_h = df_phone_watch[df_phone_watch['activity']=='H'].head(174604)\n",
    "df_f = df_phone_watch[df_phone_watch['activity']=='F'].head(174604)\n",
    "\n",
    "# balanced_data = pd.concat([df_a,df_m,df_k,df_p,df_e,df_o,df_c,df_d,df_l,df_b,df_h,df_f,df_g,df_q,df_r,df_s,df_i,df_j])\n",
    "\n",
    "# walking, sitting, standing, typing, eating, drinking from a cup\n",
    "balanced_data = pd.concat([df_a,df_d,df_e,df_f,df_h,df_k])\n",
    "\n",
    "balanced_data['activity'].value_counts()\n",
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656762</td>\n",
       "      <td>0.537032</td>\n",
       "      <td>-0.360908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100820</td>\n",
       "      <td>0.599750</td>\n",
       "      <td>-0.104312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344876</td>\n",
       "      <td>1.508825</td>\n",
       "      <td>0.328606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941948</td>\n",
       "      <td>2.589128</td>\n",
       "      <td>0.521020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.088156</td>\n",
       "      <td>1.335338</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042429</th>\n",
       "      <td>0.073083</td>\n",
       "      <td>-0.435179</td>\n",
       "      <td>-0.721587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042430</th>\n",
       "      <td>0.063613</td>\n",
       "      <td>-0.443180</td>\n",
       "      <td>-0.721878</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042431</th>\n",
       "      <td>0.075729</td>\n",
       "      <td>-0.406471</td>\n",
       "      <td>-0.723542</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042432</th>\n",
       "      <td>0.083889</td>\n",
       "      <td>-0.433519</td>\n",
       "      <td>-0.740491</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042433</th>\n",
       "      <td>0.087832</td>\n",
       "      <td>-0.449405</td>\n",
       "      <td>-0.729558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042434 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y         z  label\n",
       "0        0.656762  0.537032 -0.360908      0\n",
       "1        0.100820  0.599750 -0.104312      0\n",
       "2        0.344876  1.508825  0.328606      0\n",
       "3        0.941948  2.589128  0.521020      0\n",
       "4       -0.088156  1.335338  0.040072      0\n",
       "...           ...       ...       ...    ...\n",
       "1042429  0.073083 -0.435179 -0.721587      5\n",
       "1042430  0.063613 -0.443180 -0.721878      5\n",
       "1042431  0.075729 -0.406471 -0.723542      5\n",
       "1042432  0.083889 -0.433519 -0.740491      5\n",
       "1042433  0.087832 -0.449405 -0.729558      5\n",
       "\n",
       "[1042434 rows x 4 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label = LabelEncoder()\n",
    "balanced_data['label'] = label.fit_transform(balanced_data['activity']) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = balanced_data[['x','y','z']]\n",
    "y = balanced_data['label']\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "scaled_x = pd.DataFrame(data=x, columns=['x','y','z'])\n",
    "scaled_x['label'] = y.values\n",
    "\n",
    "scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_columns = scaled_x.iloc[:, 0:3]\n",
    "y_columns = scaled_x.iloc[:, 3:4]\n",
    "\n",
    "# sklearn split\n",
    "trainx, testx, trainy, testy = train_test_split(x_columns, y_columns, test_size=0.3, shuffle=True)\n",
    "\n",
    "# dont use sklearn split\n",
    "# test_size = 0.2\n",
    "# np.random.seed(42)\n",
    "# indices = np.random.permutation(x_columns.shape[0])\n",
    "\n",
    "# num_test_samples = int(test_size * x_columns.shape[0])\n",
    "\n",
    "# test_indices = indices[:num_test_samples]\n",
    "# train_indices = indices[num_test_samples:]\n",
    "\n",
    "# trainx = x_columns[train_indices]\n",
    "# trainy = y_columns[train_indices]\n",
    "# testx = x_columns[test_indices]\n",
    "# testy = y_columns[test_indices]\n",
    "\n",
    "assert(len(trainx) == len(trainy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequencing Data for Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.05147043 -0.471967    1.15794315]\n",
      "  [ 1.13917797 -0.62486472  0.41156093]\n",
      "  [ 0.20836606  0.78946936 -1.8260234 ]\n",
      "  ...\n",
      "  [ 0.84140207 -0.29354095 -0.09083322]\n",
      "  [-1.08376309 -0.04740406 -1.21849575]\n",
      "  [ 0.09055826 -0.50318748 -0.80106937]]\n",
      "\n",
      " [[-1.19830981  0.56429075  1.22015087]\n",
      "  [-0.98487969  1.5771408  -0.86690908]\n",
      "  [ 1.18710315  0.89561097  1.1018462 ]\n",
      "  ...\n",
      "  [ 0.17785293 -1.1999606  -0.32494475]\n",
      "  [ 1.58344703 -1.26458003 -0.60146498]\n",
      "  [-1.39481518 -0.4958793   0.54606317]]\n",
      "\n",
      " [[-1.45159178 -0.56179482 -0.39878068]\n",
      "  [-0.2573396   1.00359182  0.7064311 ]\n",
      "  [-0.1890276  -0.87086099 -1.51831736]\n",
      "  ...\n",
      "  [-2.26444776  0.36327787  0.70030733]\n",
      "  [-0.11501482  0.1394878  -0.27953678]\n",
      "  [-0.46304203  0.06723862 -2.04628318]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.97047202 -0.67746811 -1.47560621]\n",
      "  [ 0.95962074 -0.75558768  0.28995881]\n",
      "  [-0.21714494  0.83028405  1.34560515]\n",
      "  ...\n",
      "  [ 0.99354943 -0.75520925 -0.15664433]\n",
      "  [-1.22177624  1.38680368 -1.12532622]\n",
      "  [-0.61708374  1.78720761 -0.00843676]]\n",
      "\n",
      " [[-0.65952474 -0.72185216  0.20192176]\n",
      "  [ 1.16490044  0.45633055  1.01706351]\n",
      "  [ 0.1232863   0.10738451  0.77161424]\n",
      "  ...\n",
      "  [ 2.25927966 -0.13234276 -1.45242578]\n",
      "  [-0.35540351 -0.95100527  0.53025452]\n",
      "  [-0.72352701 -0.8849618   0.40339657]]\n",
      "\n",
      " [[-0.51739219  0.43466999  1.4826576 ]\n",
      "  [-0.56189383 -0.09208572 -1.12923187]\n",
      "  [ 0.12068813  0.66344092  0.25485512]\n",
      "  ...\n",
      "  [ 0.63125957 -0.61138489  0.24088097]\n",
      "  [ 1.5285696   0.40530949  0.9384631 ]\n",
      "  [ 0.20240795  1.33750644  0.84129641]]] [1 1 1 1 1 1 1 1 1 5]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "WINDOW_LENGTH = 100\n",
    "STRIDE_LENGTH = 3\n",
    "# NUM_CLASSES = 18\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 3\n",
    "\n",
    "def sequence_generator(x, y, length, stride):\n",
    "    seq_x = []\n",
    "    seq_y = []\n",
    "    data_length = len(x)\n",
    "\n",
    "    for i in range(0, data_length - length + 1, stride):\n",
    "        input_sequence = x.iloc[i : i + length]\n",
    "        target_sequence = y.iloc[i : i + length]\n",
    "        target_mode = mode(target_sequence.values)[0][0]\n",
    "        seq_x.append(input_sequence)\n",
    "        seq_y.append(target_mode)\n",
    "    return np.array(seq_x), np.array(seq_y)\n",
    "\n",
    "tx, ty = sequence_generator(trainx, trainy, WINDOW_LENGTH, STRIDE_LENGTH)\n",
    "vx, vy = sequence_generator(testx, testy, WINDOW_LENGTH, STRIDE_LENGTH)\n",
    "\n",
    "print(tx[:10], ty[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "tty = to_categorical(ty, num_classes=NUM_CLASSES)\n",
    "vvy = to_categorical(vy, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining LSTM-based Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zehaokou/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_31 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m67,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,870</span> (331.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,870\u001b[0m (331.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,870</span> (331.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,870\u001b[0m (331.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input((WINDOW_LENGTH, NUM_FEATURES)))\n",
    "model.add(LSTM(128, input_shape=(NUM_FEATURES, NUM_FEATURES), return_sequences=False))\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(LSTM(64, return_sequences=False))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m112/191\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 364ms/step - accuracy: 0.1985 - loss: 2.5729"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[303], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min', restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model.fit(tx, tty, validation_split=0.2, epochs=EPOCHS_SIZE, batch_size=BATCH_SIZE, callbacks=[early_stopping])\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_SIZE = 100\n",
    "BATCH_SIZE = 1024\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.0001, verbose=1)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min', restore_best_weights=True)\n",
    "# model.fit(tx, tty, validation_split=0.2, epochs=EPOCHS_SIZE, batch_size=BATCH_SIZE, callbacks=[early_stopping])\n",
    "\n",
    "history = model.fit(tx, tty, validation_split=0.2, epochs=EPOCHS_SIZE, batch_size=BATCH_SIZE, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.title('Model Training History')\n",
    "plt.ylabel('Loss / Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 277ms/step - accuracy: 0.2571 - loss: 2.2965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.252582311630249, 0.26434987783432007]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(vx, vvy, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - accuracy: 0.6418 - loss: 0.9843"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[283], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m test_data \u001b[38;5;241m=\u001b[39m (vx, vvy)\n\u001b[1;32m     20\u001b[0m test_callback \u001b[38;5;241m=\u001b[39m TestCallback(test_data\u001b[38;5;241m=\u001b[39mtest_data)\n\u001b[0;32m---> 22\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtest_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:354\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    349\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    351\u001b[0m     }\n\u001b[1;32m    352\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m--> 354\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/callbacks/callback_list.py:96\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     94\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[283], line 13\u001b[0m, in \u001b[0;36mTestCallback.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data\n\u001b[0;32m---> 13\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_acc\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:425\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    424\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 425\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    427\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.evaluate(vx, vvy, batch_size=BATCH_SIZE)\n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.test_loss = []\n",
    "        self.test_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        self.test_loss.append(loss)\n",
    "        self.test_acc.append(acc)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "\n",
    "# Usage\n",
    "test_data = (vx, vvy)\n",
    "test_callback = TestCallback(test_data=test_data)\n",
    "\n",
    "history = model.fit(tx, tty, validation_split=0.2, epochs=10, batch_size=BATCH_SIZE, callbacks=[test_callback])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(test_callback.test_acc)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(test_callback.test_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): ModuleList(\n",
       "    (0): LSTM(3, 7, batch_first=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=700, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        lstm_layers = []\n",
    "        for i in range(num_layers):\n",
    "            lstm_layers.append(nn.LSTM(input_dim if i == 0 else hidden_dim, hidden_dim, num_layers=1, batch_first=True, dropout=0.1 if i < num_layers - 1 else 0))\n",
    "        self.lstm = nn.ModuleList(lstm_layers)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(hidden_dim * WINDOW_LENGTH, 128) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for lstm_layer in self.lstm:\n",
    "            x, _ = lstm_layer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.num_features = num_features  # e.g., 3 for accelerometer XYZ axes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_features, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=100, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time_steps, num_features)\n",
    "        # Permute to fit Conv1d input requirement: (batch, channels, time_steps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # Conv layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        x = x.permute(0, 2, 1)  # Change back to (batch, time_steps, features)\n",
    "\n",
    "        # LSTM layer\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Take the last hidden state\n",
    "        x = hn[-1]\n",
    "\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "WINDOW_LENGTH = 100\n",
    "NUM_FEATURES = 3\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "net = LSTMModel(NUM_FEATURES, 7, 1, NUM_CLASSES)\n",
    "# net = CNNLSTMModel(num_features=NUM_FEATURES, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(tx, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(tty, dtype=torch.long)  # Assuming y_train is already categorical\n",
    "x_test_tensor = torch.tensor(vx, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(vvy, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "net.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "FOLD 1/5\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 1.8597\n",
      "------------------------------ \n",
      " epoch 1\n",
      "Validation Loss: 1.8120\n",
      "------------------------------ \n",
      " epoch 2\n",
      "Validation Loss: 1.7885\n",
      "------------------------------ \n",
      " epoch 3\n",
      "Validation Loss: 1.7733\n",
      "------------------------------ \n",
      " epoch 4\n",
      "Validation Loss: 1.7525\n",
      "------------------------------ \n",
      " epoch 5\n",
      "Validation Loss: 1.7536\n",
      "------------------------------ \n",
      " epoch 6\n",
      "Validation Loss: 1.8255\n",
      "------------------------------ \n",
      " epoch 7\n",
      "Validation Loss: 1.7900\n",
      "------------------------------ \n",
      " epoch 8\n",
      "Validation Loss: 1.7761\n",
      "------------------------------ \n",
      " epoch 9\n",
      "Validation Loss: 1.7630\n",
      "------------------------------ \n",
      " epoch 10\n",
      "Validation Loss: 1.7845\n",
      "------------------------------ \n",
      " epoch 11\n",
      "Validation Loss: 1.7610\n",
      "------------------------------ \n",
      " epoch 12\n",
      "Validation Loss: 1.7584\n",
      "------------------------------ \n",
      " epoch 13\n",
      "Validation Loss: 1.7510\n",
      "------------------------------ \n",
      " epoch 14\n",
      "Validation Loss: 1.7626\n",
      "------------------------------ \n",
      " epoch 15\n",
      "Validation Loss: 1.7501\n",
      "------------------------------ \n",
      " epoch 16\n",
      "Validation Loss: 1.7510\n",
      "------------------------------ \n",
      " epoch 17\n",
      "Validation Loss: 1.7617\n",
      "------------------------------ \n",
      " epoch 18\n",
      "Validation Loss: 1.7482\n",
      "------------------------------ \n",
      " epoch 19\n",
      "Validation Loss: 1.7682\n",
      "------------------------------ \n",
      " epoch 20\n",
      "Validation Loss: 1.7424\n",
      "------------------------------ \n",
      " epoch 21\n",
      "Validation Loss: 1.7743\n",
      "------------------------------ \n",
      " epoch 22\n",
      "Validation Loss: 1.7472\n",
      "------------------------------ \n",
      " epoch 23\n",
      "Validation Loss: 1.7545\n",
      "------------------------------ \n",
      " epoch 24\n",
      "Validation Loss: 1.7564\n",
      "------------------------------ \n",
      " epoch 25\n",
      "Validation Loss: 1.7486\n",
      "------------------------------ \n",
      " epoch 26\n",
      "Validation Loss: 1.7407\n",
      "------------------------------ \n",
      " epoch 27\n",
      "Validation Loss: 1.7486\n",
      "------------------------------ \n",
      " epoch 28\n",
      "Validation Loss: 1.7492\n",
      "------------------------------ \n",
      " epoch 29\n",
      "Validation Loss: 1.7498\n",
      "------------------------------ \n",
      " epoch 30\n",
      "Validation Loss: 1.7869\n",
      "------------------------------ \n",
      " epoch 31\n",
      "Validation Loss: 1.7489\n",
      "------------------------------ \n",
      " epoch 32\n",
      "Validation Loss: 1.7467\n",
      "------------------------------ \n",
      " epoch 33\n",
      "Validation Loss: 1.7462\n",
      "------------------------------ \n",
      " epoch 34\n",
      "Validation Loss: 1.7365\n",
      "------------------------------ \n",
      " epoch 35\n",
      "Validation Loss: 1.7400\n",
      "------------------------------ \n",
      " epoch 36\n",
      "Validation Loss: 1.7398\n",
      "------------------------------ \n",
      " epoch 37\n",
      "Validation Loss: 1.7713\n",
      "------------------------------ \n",
      " epoch 38\n",
      "Validation Loss: 1.7511\n",
      "------------------------------ \n",
      " epoch 39\n",
      "Validation Loss: 1.7395\n",
      "------------------------------ \n",
      " epoch 40\n",
      "Validation Loss: 1.7636\n",
      "------------------------------ \n",
      " epoch 41\n",
      "Validation Loss: 1.7351\n",
      "------------------------------ \n",
      " epoch 42\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "train_accuracies = []\n",
    "print(\"Start Training...\")\n",
    "\n",
    "patience = 10  \n",
    "n_folds = 5 \n",
    "num_epochs = 100\n",
    "\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
    "early_stop_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_loader.dataset)):\n",
    "    print(f\"FOLD {fold + 1}/{n_folds}\")\n",
    "\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    trainloader_fold = torch.utils.data.DataLoader(train_loader.dataset, batch_size=1024, sampler=train_subsampler)\n",
    "    valloader_fold = torch.utils.data.DataLoader(train_loader.dataset, batch_size=1024, sampler=val_subsampler)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 30, '\\n', 'epoch', epoch)\n",
    "        net.train()\n",
    "        loss100 = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader_fold):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            if labels.dim() > 1:  # This checks if labels are not 1D\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss100 += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader_fold):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                if labels.dim() > 1:  # This checks if labels are not 1D\n",
    "                    labels = torch.argmax(labels, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(valloader_fold)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "plt.plot(train_accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing...\n",
      "Test Loss: 1.9422, Test Accuracy: 16.99%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Start Testing...\")\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        if labels.dim() > 1:  # Check if labels are not 1D, useful for one-hot encoded labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy()) \n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = correct / total * 100\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "class_names = ['A', 'B', 'D', 'E','F', 'H', 'K']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.5161, Accuracy: 0.1517\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = test_model(net, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels data type before loss calculation: torch.int64\n",
      "Outputs shape: torch.Size([1024, 18])\n",
      "Outputs type: torch.float32\n",
      "Labels shape: torch.Size([1024, 18])\n",
      "Labels type: torch.int64\n",
      "Epoch [1/10], Loss: 2.0093\n",
      "Epoch [2/10], Loss: 1.6457\n",
      "Epoch [3/10], Loss: 1.1824\n",
      "Epoch [4/10], Loss: 0.7026\n",
      "Epoch [5/10], Loss: 0.9689\n",
      "Epoch [6/10], Loss: 0.6267\n",
      "Epoch [7/10], Loss: 0.9258\n",
      "Epoch [8/10], Loss: 0.8332\n",
      "Epoch [9/10], Loss: 0.5801\n",
      "Epoch [10/10], Loss: 0.5268\n"
     ]
    }
   ],
   "source": [
    "def train_model(num_epochs, model, train_loader, criterion, optimizer):\n",
    "    model.train()  # Set the model to training mode.\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Correct the shape of labels if necessary\n",
    "            if labels.dim() > 1:  # This checks if labels are not 1D\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Check label data type right before the loss calculation\n",
    "print(\"Labels data type before loss calculation:\", labels.dtype)\n",
    "\n",
    "print(\"Outputs shape:\", outputs.shape)  # Should be [batch_size, num_classes]\n",
    "print(\"Outputs type:\", outputs.dtype)   # Should be torch.float32\n",
    "print(\"Labels shape:\", labels.shape)   # Should be [batch_size]\n",
    "print(\"Labels type:\", labels.dtype)    # Should be torch.long\n",
    "\n",
    "train_model(10, net, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m             correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mcorrect\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(net, test_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 22\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(out)\n\u001b[1;32m     24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/torch/nn/modules/rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0"
     ]
    }
   ],
   "source": [
    "def evaluate_model(net, test_loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate_model(net, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.3948 - loss: 1.9136\n",
      "Epoch 2/100\n",
      "\u001b[1m 13/983\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.4922 - loss: 1.3578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zehaokou/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5099 - loss: 1.3232\n",
      "Epoch 3/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5365 - loss: 1.2650\n",
      "Epoch 4/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.5671 - loss: 1.2087\n",
      "Epoch 5/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.5861 - loss: 1.1614\n",
      "Epoch 6/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.5945 - loss: 1.1317\n",
      "Epoch 7/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6001 - loss: 1.1124\n",
      "Epoch 8/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6051 - loss: 1.0970\n",
      "Epoch 9/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6115 - loss: 1.0808\n",
      "Epoch 10/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6133 - loss: 1.0716\n",
      "Epoch 11/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6170 - loss: 1.0655\n",
      "Epoch 12/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6209 - loss: 1.0543\n",
      "Epoch 13/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6238 - loss: 1.0447\n",
      "Epoch 14/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6253 - loss: 1.0407\n",
      "Epoch 15/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6297 - loss: 1.0366\n",
      "Epoch 16/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6318 - loss: 1.0257\n",
      "Epoch 17/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6322 - loss: 1.0259\n",
      "Epoch 18/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6335 - loss: 1.0193\n",
      "Epoch 19/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6384 - loss: 1.0112\n",
      "Epoch 20/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6382 - loss: 1.0105\n",
      "Epoch 21/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6384 - loss: 1.0067\n",
      "Epoch 22/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6403 - loss: 1.0066\n",
      "Epoch 23/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6404 - loss: 1.0068\n",
      "Epoch 24/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6384 - loss: 1.0064\n",
      "Epoch 25/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6426 - loss: 0.9998\n",
      "Epoch 26/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6406 - loss: 1.0054\n",
      "Epoch 27/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6415 - loss: 1.0013\n",
      "Epoch 28/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6421 - loss: 0.9985\n",
      "Epoch 29/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6446 - loss: 0.9958\n",
      "Epoch 30/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6439 - loss: 0.9941\n",
      "Epoch 31/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6419 - loss: 0.9989\n",
      "Epoch 32/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6421 - loss: 0.9941\n",
      "Epoch 33/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6470 - loss: 0.9895\n",
      "Epoch 34/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6461 - loss: 0.9949\n",
      "Epoch 35/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6445 - loss: 0.9953\n",
      "Epoch 36/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6477 - loss: 0.9889\n",
      "Epoch 37/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6483 - loss: 0.9897\n",
      "Epoch 38/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6467 - loss: 0.9895\n",
      "Epoch 39/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6496 - loss: 0.9829\n",
      "Epoch 40/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6468 - loss: 0.9865\n",
      "Epoch 41/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6478 - loss: 0.9849\n",
      "Epoch 42/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6492 - loss: 0.9855\n",
      "Epoch 43/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6504 - loss: 0.9793\n",
      "Epoch 44/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6493 - loss: 0.9803\n",
      "Epoch 45/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6492 - loss: 0.9776\n",
      "Epoch 46/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6475 - loss: 0.9863\n",
      "Epoch 47/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6500 - loss: 0.9820\n",
      "Epoch 48/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6493 - loss: 0.9811\n",
      "Epoch 49/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6482 - loss: 0.9839\n",
      "Epoch 50/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6488 - loss: 0.9827\n",
      "Epoch 51/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6498 - loss: 0.9797\n",
      "Epoch 52/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6510 - loss: 0.9777\n",
      "Epoch 53/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6481 - loss: 0.9836\n",
      "Epoch 54/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6513 - loss: 0.9788\n",
      "Epoch 55/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6462 - loss: 0.9857\n",
      "Epoch 56/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6470 - loss: 0.9840\n",
      "Epoch 57/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6501 - loss: 0.9767\n",
      "Epoch 58/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6494 - loss: 0.9794\n",
      "Epoch 59/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6482 - loss: 0.9803\n",
      "Epoch 60/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6494 - loss: 0.9760\n",
      "Epoch 61/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6506 - loss: 0.9798\n",
      "Epoch 62/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6491 - loss: 0.9786\n",
      "Epoch 63/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6501 - loss: 0.9767\n",
      "Epoch 64/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6493 - loss: 0.9792\n",
      "Epoch 65/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6496 - loss: 0.9774\n",
      "Epoch 66/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6526 - loss: 0.9768\n",
      "Epoch 67/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6503 - loss: 0.9774\n",
      "Epoch 68/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6533 - loss: 0.9731\n",
      "Epoch 69/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6527 - loss: 0.9732\n",
      "Epoch 70/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6536 - loss: 0.9688\n",
      "Epoch 71/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6511 - loss: 0.9757\n",
      "Epoch 72/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6526 - loss: 0.9709\n",
      "Epoch 73/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6525 - loss: 0.9730\n",
      "Epoch 74/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6538 - loss: 0.9725\n",
      "Epoch 75/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6506 - loss: 0.9789\n",
      "Epoch 76/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6562 - loss: 0.9671\n",
      "Epoch 77/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6511 - loss: 0.9758\n",
      "Epoch 78/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6525 - loss: 0.9706\n",
      "Epoch 79/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6541 - loss: 0.9675\n",
      "Epoch 80/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6559 - loss: 0.9622\n",
      "Epoch 81/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6541 - loss: 0.9668\n",
      "Epoch 82/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6509 - loss: 0.9776\n",
      "Epoch 83/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6555 - loss: 0.9663\n",
      "Epoch 84/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6558 - loss: 0.9662\n",
      "Epoch 85/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6513 - loss: 0.9695\n",
      "Epoch 86/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6553 - loss: 0.9632\n",
      "Epoch 87/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6534 - loss: 0.9718\n",
      "Epoch 88/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6540 - loss: 0.9654\n",
      "Epoch 89/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6535 - loss: 0.9694\n",
      "Epoch 90/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6501 - loss: 0.9714\n",
      "Epoch 91/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6520 - loss: 0.9709\n",
      "Epoch 92/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6548 - loss: 0.9647\n",
      "Epoch 93/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6532 - loss: 0.9664\n",
      "Epoch 94/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6538 - loss: 0.9665\n",
      "Epoch 95/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6533 - loss: 0.9651\n",
      "Epoch 96/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6537 - loss: 0.9648\n",
      "Epoch 97/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6539 - loss: 0.9660\n",
      "Epoch 98/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6549 - loss: 0.9592\n",
      "Epoch 99/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6528 - loss: 0.9692\n",
      "Epoch 100/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6559 - loss: 0.9581\n",
      "\u001b[1m1964/1964\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7672 - loss: 0.7601\n",
      "Epoch 1/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6231 - loss: 1.0375\n",
      "Epoch 2/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6299 - loss: 1.0201\n",
      "Epoch 3/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6298 - loss: 1.0159\n",
      "Epoch 4/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6322 - loss: 1.0084\n",
      "Epoch 5/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6335 - loss: 1.0052\n",
      "Epoch 6/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6311 - loss: 1.0079\n",
      "Epoch 7/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6329 - loss: 1.0060\n",
      "Epoch 8/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6278 - loss: 1.0380\n",
      "Epoch 9/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6336 - loss: 1.0051\n",
      "Epoch 10/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6364 - loss: 0.9985\n",
      "Epoch 11/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6376 - loss: 0.9972\n",
      "Epoch 12/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6397 - loss: 0.9915\n",
      "Epoch 13/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6403 - loss: 0.9915\n",
      "Epoch 14/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6384 - loss: 0.9948\n",
      "Epoch 15/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6428 - loss: 0.9871\n",
      "Epoch 16/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6419 - loss: 0.9893\n",
      "Epoch 17/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6426 - loss: 0.9860\n",
      "Epoch 18/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6440 - loss: 0.9810\n",
      "Epoch 19/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6420 - loss: 0.9880\n",
      "Epoch 20/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6454 - loss: 0.9799\n",
      "Epoch 21/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6457 - loss: 0.9777\n",
      "Epoch 22/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6421 - loss: 0.9926\n",
      "Epoch 23/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6449 - loss: 0.9818\n",
      "Epoch 24/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6462 - loss: 0.9784\n",
      "Epoch 25/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6466 - loss: 0.9816\n",
      "Epoch 26/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6476 - loss: 0.9793\n",
      "Epoch 27/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6464 - loss: 0.9790\n",
      "Epoch 28/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6492 - loss: 0.9766\n",
      "Epoch 29/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6475 - loss: 0.9752\n",
      "Epoch 30/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6453 - loss: 0.9817\n",
      "Epoch 31/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6495 - loss: 0.9715\n",
      "Epoch 32/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6475 - loss: 0.9773\n",
      "Epoch 33/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6478 - loss: 0.9752\n",
      "Epoch 34/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6468 - loss: 0.9834\n",
      "Epoch 35/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6481 - loss: 0.9763\n",
      "Epoch 36/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6489 - loss: 0.9735\n",
      "Epoch 37/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6487 - loss: 0.9744\n",
      "Epoch 38/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6506 - loss: 0.9711\n",
      "Epoch 39/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6477 - loss: 0.9774\n",
      "Epoch 40/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6485 - loss: 0.9756\n",
      "Epoch 41/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6503 - loss: 0.9713\n",
      "Epoch 42/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6505 - loss: 0.9706\n",
      "Epoch 43/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6475 - loss: 0.9787\n",
      "Epoch 44/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6452 - loss: 0.9825\n",
      "Epoch 45/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6498 - loss: 0.9732\n",
      "Epoch 46/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6509 - loss: 0.9731\n",
      "Epoch 47/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6481 - loss: 0.9742\n",
      "Epoch 48/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6495 - loss: 0.9709\n",
      "Epoch 49/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6496 - loss: 0.9664\n",
      "Epoch 50/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6492 - loss: 0.9803\n",
      "Epoch 51/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6497 - loss: 0.9729\n",
      "Epoch 52/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6491 - loss: 0.9695\n",
      "Epoch 53/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.6525 - loss: 0.9674\n",
      "Epoch 54/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6457 - loss: 0.9828\n",
      "Epoch 55/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6513 - loss: 0.9647\n",
      "Epoch 56/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6504 - loss: 0.9648\n",
      "Epoch 57/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6495 - loss: 0.9665\n",
      "Epoch 58/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6483 - loss: 0.9720\n",
      "Epoch 59/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.6499 - loss: 0.9672\n",
      "Epoch 60/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6495 - loss: 0.9662\n",
      "Epoch 61/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6494 - loss: 0.9697\n",
      "Epoch 62/100\n",
      "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.6506 - loss: 0.9680\n",
      "Epoch 63/100\n",
      "\u001b[1m199/983\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6493 - loss: 0.9628"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m tty \u001b[38;5;241m=\u001b[39m to_categorical(ty, num_classes \u001b[38;5;241m=\u001b[39m NUM_CLASSES)\n\u001b[1;32m     23\u001b[0m vvy \u001b[38;5;241m=\u001b[39m to_categorical(vy, num_classes \u001b[38;5;241m=\u001b[39m NUM_CLASSES)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(vx, vvy)\n\u001b[1;32m     28\u001b[0m lst_accu_stratified\u001b[38;5;241m.\u001b[39mappend(test_accuracy)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "EPOCHS_SIZE = 100\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "NUM_SPLITS = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits = NUM_SPLITS, shuffle=False)\n",
    "lst_accu_stratified = []\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "for train_index, test_index in skf.split(x_columns, y_columns):\n",
    "    x_train_fold, x_test_fold = x_columns.iloc[train_index], x_columns.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_columns.iloc[train_index], y_columns.iloc[test_index]\n",
    "    \n",
    "    tx, ty = sequence_generator(x_train_fold, y_train_fold, WINDOW_LENGTH, STRIDE_LENGTH)\n",
    "    vx, vy = sequence_generator(x_test_fold, y_test_fold, WINDOW_LENGTH, STRIDE_LENGTH)\n",
    "\n",
    "\n",
    "    tty = to_categorical(ty, num_classes = NUM_CLASSES)\n",
    "    vvy = to_categorical(vy, num_classes = NUM_CLASSES)\n",
    "\n",
    "    model.fit(tx, tty, epochs=EPOCHS_SIZE, batch_size=BATCH_SIZE, callbacks=[early_stopping])\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(vx, vvy)\n",
    "    lst_accu_stratified.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6346001029014587]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 0.6346001029014587\n",
      "\n",
      "Minimum Accuracy: 0.6346001029014587\n",
      "\n",
      "Overall Accuracy: 0.6346001029014587\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "variance requires at least two data points",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMinimum Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mmin\u001b[39m(lst_accu_stratified))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOverall Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, mean(lst_accu_stratified))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStandard Deviation is:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mstdev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlst_accu_stratified\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/statistics.py:828\u001b[0m, in \u001b[0;36mstdev\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the square root of the sample variance.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03mSee ``variance`` for arguments and other details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m \n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# Fixme: Despite the exact sum of squared deviations, some inaccuracy\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# remain because there are two rounding steps.  The first occurs in\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# the _convert() step for variance(), the second occurs in math.sqrt().\u001b[39;00m\n\u001b[0;32m--> 828\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[43mvariance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m var\u001b[38;5;241m.\u001b[39msqrt()\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.10/statistics.py:767\u001b[0m, in \u001b[0;36mvariance\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    765\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariance requires at least two data points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    768\u001b[0m T, ss \u001b[38;5;241m=\u001b[39m _ss(data, xbar)\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(ss \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), T)\n",
      "\u001b[0;31mStatisticsError\u001b[0m: variance requires at least two data points"
     ]
    }
   ],
   "source": [
    "from statistics import stdev, mean\n",
    "\n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:', max(lst_accu_stratified))\n",
    "print('\\nMinimum Accuracy:', min(lst_accu_stratified))\n",
    "print('\\nOverall Accuracy:', mean(lst_accu_stratified))\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
